# 底层数据结构

## JDK 1.8之前

使用 **数组+链表**，其中 `hash` 函数扰动了 **4**次。

使用**拉链法**，即创建一个数组，数组的每一格就是一个链表。若遇到哈希冲突，将冲突的值加到链表中去。

## JDK 1.8之后

使用 **数组+链表/红黑树**，其中 `hash` 函数扰动了**1** 次

```java
(h = key.hashCode()) ^ (h >>> 16)
```

当链表长度大于**8**时，调用**treeifyBin()**，只有当数组长度是否**大于等于64**，执行转换成红黑树，否则只是执行 `resize()` 对数组进行扩容。

# hash函数

## 为什么hashMap的数组长度为2的整数幂

由于hash值是一个**int类型**的值, 大部分情况下hashMap是不会有这么长的, 所以在有限的长度内, 取hash值的低几位是比较理想的**散列方式**.

而任何2的整数幂, 再减一后的**二进制变为前面均为0后面均为1的结构**. 所以让hash值**&**上**n-1**后就可以获取低位的hash值，在使用低位的 hash 值作为数组的索引。

```
    00100100 10100101 11000100 00100101    // Hash 值 
&   00000000 00000000 00000000 00001111    // 16 - 1 = 15
----------------------------------
    00000000 00000000 00000000 00000101    // 高位全部归零，只保留末四位。
```

## hash算法(扰动函数)

所以我们想要后几位足够散列, 才能减少碰撞次数. 而如果只是取后几位的话, 则高位不同, 但是低位相同的 hash 值就很容易碰撞了. 所以采取的方式就是**将 hash 值的高 16 位与低 16 位取异或运算**, 得到一个更加散列的低 16 位的 hash 值.

```
00000000 00000000 00000000 00000101 // H1
00000000 00000000 00000000 00000000 // H1 >>> 16
00000000 00000000 00000000 00000101 // hash = H1 ^ (H1 >>> 16) = 5

00000000 11111111 00000000 00000101 // H2
00000000 00000000 00000000 11111111 // H2 >>> 16
00000000 00000000 00000000 11111010 // hash = H2 ^ (H2 >>> 16) = 250

```

# put()函数

```java
HashMap<String, Integer> map = new HashMap<>();
map.put("Mike", 20);
```

## 主要流程

调用 put() 方法传入键值对 =》根据 Hash 算法算出 Hash 值 =〉根据 Hash 值计算存放的位置，并判断是否起冲突 =》若没有冲突，判断当前结构是什么 =〉若是红黑树，插入红黑树中 =》若是链表，判断插入后链表长度是否大于 8 =〉若插入大于8，则线调整为红黑树后再插入 =》若插入后链表长度不大于8 =〉则直接插入**链表尾部**即可。

## 代码

1. put() 方法内部调用 putVal() , 传入 hash 值和 key value
2. 判断当前数组是否为空，若为空则调用 **resize()** 进行扩容
3. 计算插入位置 **i = (n - 1) & hash**，若插入位置不冲突，则创建新的Node节点
4. 若冲突了：
   1. 判断两者 key 值是否相同，相同直接替换 value
   2. 不然判断当前数据结构是否是红黑树，如果是，则创建新的 Node 调用 putTreeVal() 插入到红黑树中
   3. 否则就是链表，遍历该链表是否有对应的相同的 key，存在则直接替换 value，不存在则创建新的 Node 插入链表。插入后判断判断当前链表长度是否大于8，若大于则调用 **treeifyBin()** 转为红黑树。
5. 插入成功后还要判断一下实际的键值对数量 size 是否大于阈值 **threshold**，如果大于就调用 **resize()** 扩容

# resize()扩容

## 主要流程

HaspMap扩容就是就是先计算 新的hash表容量和新的容量阀值，然后初始化一个新的hash表，将旧的键值对重新映射在新的hash表里。如果在旧的hash表里涉及到红黑树，那么在映射到新的hash表中还涉及到红黑树的拆分。

## 代码

1. 若数组有元素，且超过了数组最大容量，直接将阈值设置为整数最大值，如果没有超过，就直接扩容为**原来的 2 倍**（使用 oldThr << 1，左移操作）

2. 若数组没有元素，且阈值已经初始化了，就直接使用该阈值。不然就初始化一个默认的容量和阈值。

3. 之后将旧的数据复制到新的数组里面。

   1. 如果只有一个节点，则通过索引位置直接映射。

      ```java
      newTab[e.hash & (newCap - 1)] = e;
      ```

   2. 如果是红黑树，则将树拆分后映射

   3. 如果是多节点链表，将原链表拆分为两个链表，一个链表存放在原位置，一个链表切换位置。

      最简单的方法就是轮询这个链表，然后使用 hash & (n - 1) 来判断新的索引位置。但是通过计算新索引可以发现规律，就是有一部分节点在原位置，有一部分在新位置，**且是否移动可以通过 hash & 旧容量的第一位**来确定，如果是 0 ，则不需要移动，否则需要移动，移动的位置等于**旧容量 + 当前 index**

# 构造函数

## 变量

- initialCapacity 初始容量

  要求输入一个2的N次幂，如果不是2的N次幂，则会找大于该数值最近的2的N次幂

- loadFactor 负载因子

  默认是 0.75。表示一个散列表的空间的使用程度，有这样一个公式：initailCapacity*loadFactor=HashMap的容量。

   所以负载因子越大则散列表的装填程度越高，也就是能容纳更多的元素，元素多了，链表大了，所以此时索引效率就会降低。反之，负载因子越小则链表中的数据量就越稀疏，此时会对空间造成烂费，但是此时索引效率高。



