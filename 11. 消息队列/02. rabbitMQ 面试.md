# 使用MQ原因

## 解耦

A系统会生产一种消息，需要发送给BCD系统，通过调用接口发送。但是如果E系统也要这个数据或者C系统不需要了呢？这种场景下，A系统就会和其他的系统强耦合，A系统生产的数据，在发送给其他系统时还需要考虑他们的状态，是否重发等等情况。

如果使用MQ，A系统生产一条数据直接发送到MQ中去，其他系统去MQ中消费。这样，A系统不需要考虑给谁发送消息和考虑是否重发等情况，这样就可以实现低耦合。

## 异步

A系统接收请求后，需要在BCD三个系统中写库，A处理需要3ms，但是BCD写库需要300ms，总延时将近1s，是不可接受的，一般请求都要求200ms，用户才是无感知的。

如果使用MQ，用户向A发送请求后，A系统直接响应，这样总响应时间可以减少很多，提升用户体验。那么剩下的BCD三个系统写库，就异步执行。

## 削峰

当每天某个时间段请求的并发数量激增，大量请求直接打到数据库中，可能会造成数据库的瘫痪。但是在非高峰期数据请求没有那么大。

如果使用MQ的话，就可以限制系统每秒处理的数量。系统可以从MQ中慢慢拉取请求，不超过自己的最大请求数量即可，这样下来即使在高峰期也不至于会挂掉。

# ActiveMQ, RabbitMQ, RocketMQ,Kafaka, 

- 单机吞吐量

  ActiveMQ 和 RabbitMQ 是万级的，而RocketMQ 和 Kafka 是10万级的，支持高吞吐。其中 kafka 一般配合大数据类的系统来进行实时数据计算、日志采集等场景。

- Topic 数量对吞吐影响

  rocketMQ 可以支持几百-几千的级别，而 kaka 可以支持几十-几百的级别

- 时效性

  ActiveMQ , RocketMQ, Kafka 是 ms 级的，RabbitMQ 是微秒级的，这是 RabbitMQ 的一大特点，延迟最低。

- 可用性

  ActiveMQ和RabbitMQ 基于主从架构实现高可用，RocketMQ和Kafka是基于分布式实现高可用

- 消息可靠性

  ActiveMQ 有较低的概率丢失，RabbitMQ基本不丢失，RocketMQ和Kafka进过参数配置后，可以做到不丢失

- 功能支持

  ActiveMQ 在 MQ领域功能完善，RabbitMQ 基于 erlang 开发，并发性能强，性能好，延时低，RocketMQ 功能完善，且是分布式的，扩展性好，Kafka 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用。

# 如何确保消息的可靠性传输

## RabbitMQ

### 生产者丢失数据

- 使用事务

  生产者发送数据之前开启 RabbitMQ 事务 `channel.txSelect `	，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务 `channel.txRollback` ，然后重试发送消息；如果收到了消息，那么可以提交事务 `channel.txCommit` 。

  **但是开启RabbitMQ事务之后，基本上吞吐量下降，因为太好性能**

- 使用 `confirm` 机制

  开启 `confirm` 机制之后，每次写的消息都会分配一个唯一id，写入成功后 rabbitmq 会返回 `ack`消息；如果rabbitmq没能处理这个消息，会回调一个 `nack` 接口，可以尝试重发。

事务机制和`confirm`机制的不同就是，**事务机制是同步的**，提交事务之后会阻塞，但是**confirm机制是异步的**，发送一个消息之后可以立即发送下一个消息。所以一般都是使用 `confirm` 机制。

### RabbitMQ丢失数据

开启**RabbitMQ持久化**，将消息写入磁盘中，即使Rabbit MQ挂了，也可以从磁盘中读取数据。

设置持久化步骤：

1. 创建 queue 时将其设置为持久化。可以保证 rabbitmq 持久化队列的**元数据**，而不是队列里面的数据。
2. 发送消息时设置 `deliveryMode` 为 2

## 消费端弄丢数据

可能在刚消费数据时，进程挂掉了，那么数据就会丢失了。

可以使用 rabbitmq 的 ack 机制，关闭 RabbitMQ 的自动 ack ，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 ack 一次。

# 如何保证消息队列高可用

## rabbitmq高可用

RabbitMQ 是比较有代表性的具有高可用的消息队列，因为是基于主从架构做高可用的。其中 rabbitmq 使用的集群模式有两种，普通集群模式和镜像集群模式。

普通集群模式中是不具备高可用的，因为创建的queue只会存在一个rabbitmq实例上，只是每个实例都同步queue的元数据（元数据可以认为是一些配置信息，通过配置信息可以找到queue所在的实例）。当消费时，实际上是连到了另一个实例，从原来的实例上拉消息去连着的实例上消费并返回。所以这个方案主要是**提高吞吐量**，而无法提高高可用。

镜像集群模式是具备高可用的，和普通集群不一样，在镜像集群模式下，创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上。每次写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。

> 坏处就是开销太大，同时无法线性扩展queue，如果这个 queue数据量很大了，可能整个机器都无法容纳。

## kafka高可用

kafka架构，是由多个broker组成，每个broker作为一个节点；当创建一个topic，这个topic可以划分为多个partition，每个partition可以存在不同的broker上，每个partition可以放一部分数据。

这就是天然的分布式消息队列，也就是说一个 topic 的数据，是分散在多个机器上的，每个机器放一部分数据。

Kafka0.8以前，没有 HA 机制，任意一个broker宕机了，那个broker上的partition就报废了，没法读没法写。

kafka0.8之后，提供了HA机制，就是 replica 复制品机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就同步。写的时候，leader会负责同步到所有复制品上，读的时候直接从leader上读。

这样就具备了高可用，因为如果某个 broker 宕机了，没事儿，那个 broker 上面的 partition 在其他机器上都有副本的。

# 如何避免消息重复消费/投递

在消息生产时，MQ内部对每个消息都生成一个唯一ID，作为去重的依据，避免重复入队。在消息消费时，要求消息中有一个唯一的业务ID，如支付ID、订单ID等。

# 消息基于什么传输

由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。

abbitMQ 使用**信道**的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。

# 消息如何路由

消息在初始化时中会绑定一个**路由键**，同时通过**队列路由键**，可以把队列绑定到交换器上。消息到达交换器时，rabbitmq 会将消息的路由键与队列的路由键进行匹配，针对不同的交换器有不同的路由规则。

常见的交换器有三种

- Fanout: 将消息广播到所有绑定的队列上
- Direct: 路由键完全匹配，消息被投到相应的队列
- topic: 使用通配符，只要满足要求就投到相应的队列

# 多消费者，如何分发消息

**轮询**：默认的策略，消费者轮流、平均接收消息

**公平分发**：根据消费者的能力来分发消息，给空闲的消费者发送更多消息

# 无法路由的消息去哪儿

无设置的情况下，无法路由（Routing key错误）的消息会被直接丢弃。解决方法是将 **mandatory** 设置为 true，实现消息的回发。

# 消息何时变为死信

消息拒绝且没有设置重新入队、消息过期、消息堆积

# 实现延时队列

利用TTL，即队列的消息存活时间或者消息的存活时间，再加上死信交换机

```java
// 设置属性，消息10秒钟过期
        AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
                .expiration("10000") // TTL

 // 指定队列的死信交换机
        Maparguments = new HashMap();
        arguments.put("x-dead-letter-exchange","DLX_EXCHANGE");
```

# 如何保证消息幂等

生产者对每条消息生成一个唯一ID，以控制消息重复投递。消费者中每个消息体必须携带一个业务ID，如订单ID等，消费者可以根据业务ID去重，避免重复消费。

# 如何优先消费

设立消费的优先级

```java
//生产者
 Mapargss = new HashMap();
        argss.put("x-max-priority",10);

//消费者
AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
                .priority(5) // 优先级，默认为5，配合队列的 x-max-priority 属性使用
```

## 如何保证消息的顺序性

一个队列一个消费者的情况下可以实现，否则只能够使用全局ID。可以在消费者端实现前一条未消费不处理下一条；也可以在生产端实现前一条消息未处理完，不发布下一条。

# AMPQ

RabbitMQ就是 AMQP 协议的 Erlang 的实现(当然 RabbitMQ 还支持 STOMP2、 MQTT3 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定 。

## 三层协议

- **Module Layer:**协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。
- **Session Layer**:中间层，主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理。
- **TransportLayer**:最底层，主要传输二进制数据流，提供帧的处理、信道服用、错误检测和数据表示等。

## 组件

- 交换器 (Exchange)：消息代理服务器中用于把消息**路由到**队列的组件。
- 队列 (Queue)：用来存储消息的数据结构，位于硬盘或内存中。
- 绑定 (Binding)： 一套规则，告知交换器消息应该将消息投递给哪个队列。

# 队列结构

**rabbit_amqqueue_process**：负责协议相关的消息处理，即接收生产者发布的消息、向消费者交付消息、处理消息的确认(包括生产端的 confirm 和消费端的 ack) 等

**backing_queue**：是消息存储的具体形式和引擎，并向 rabbit amqqueue process 提供相关的接口以供调用。

# 消息的状态

alpha: 消息内容(包括消息体、属性和 headers) 和消息索引都存储在内存中 。

beta: 消息内容保存在磁盘中，消息索引保存在内存中。

gamma: 消息内容保存在磁盘中，消息索引在磁盘和内存中都有 。

delta: 消息内容和索引都在磁盘中 。